{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo: \n",
    "+ ~~期待値がほぼ 0 になっている理由を探す。回避できるようなら回避~~\n",
    "+ ~~C = 3 * n_qubits の理由~~ (特に理由はない？)\n",
    "+ ~~QPU のばらつき改善~~\n",
    "+ ~~2 次のトロッターにしてみる~~\n",
    "+ ~~GHZ を中心に寄せる。このままだと不要な Trotter gate があるので。~~\n",
    "+ 不要な interaction を削除"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## わかったこと\n",
    "+ ハミルトニアンをシフトさせなければ成功\n",
    "+ times = [2 * np.pi * k / C for k in range(n_features)] は失敗\n",
    "+ times = [np.pi * k / C for k in range(n_features)] は成功"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pip freeze > requirements.txt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/jovyan',\n",
      " '/opt/conda/lib/python311.zip',\n",
      " '/opt/conda/lib/python3.11',\n",
      " '/opt/conda/lib/python3.11/lib-dynload',\n",
      " '',\n",
      " '/opt/conda/lib/python3.11/site-packages',\n",
      " '/home/jovyan/fourier_learning_ibm/']\n"
     ]
    }
   ],
   "source": [
    "# Add the fourier_learning_ibm package to the path\n",
    "import sys, pprint\n",
    "\n",
    "sys.path.append(\"/home/jovyan/fourier_learning_ibm/\")\n",
    "pprint.pprint(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from heisenberg_graph import (\n",
    "    HeisenbergModel,\n",
    "    get_n_steps,\n",
    "    get_graph,\n",
    "    get_positions,\n",
    "    get_initial_layout,\n",
    "    get_prob0,\n",
    "    extract_probs,\n",
    ")\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.quantum_info.operators import Operator\n",
    "from qiskit.quantum_info import SparsePauliOp, Statevector\n",
    "from qiskit.circuit.library import PauliEvolutionGate\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService, SamplerV2 as Sampler, Batch\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit_aer.noise import NoiseModel\n",
    "import mthree\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from datetime import datetime, timezone\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Qiskit Runtime service (this is a one-time setup)\n",
    "# QiskitRuntimeService.save_account(\n",
    "#     token=\"YOUR_API_TOKEN\",\n",
    "#     channel=\"ibm_quantum\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using backend QPU: <IBMBackend('ibm_marrakesh')>\n",
      "Using backend simulator: AerSimulator('aer_simulator')\n",
      "Using backend noisy simulator: AerSimulator('aer_simulator'\n",
      "             noise_model=<NoiseModel on ['x', 'cz', 'id', 'measure', 'reset', 'sx']>)\n"
     ]
    }
   ],
   "source": [
    "# Option1: Use IBM Quantum backend.\n",
    "# Load saved credentials\n",
    "service = QiskitRuntimeService()\n",
    "# backend_qpu = service.least_busy(simulator=False, interactional=True)\n",
    "backend_qpu = service.backend(\"ibm_marrakesh\")\n",
    "\n",
    "# Option2: Use local AerSimulator as the backend.\n",
    "backend_sim = AerSimulator()\n",
    "\n",
    "noise_model = NoiseModel.from_backend(backend_qpu)\n",
    "backend_sim_noisy = AerSimulator(noise_model=noise_model)\n",
    "\n",
    "print(f\"Using backend QPU: {backend_qpu}\")\n",
    "print(f\"Using backend simulator: {backend_sim}\")\n",
    "print(f\"Using backend noisy simulator: {backend_sim_noisy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセット作成 $\\exp(-\\beta H)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 70\n",
    "n_qubits = 10\n",
    "beta = 1\n",
    "\n",
    "graph_type = \"line\"\n",
    "# ghz_qubits = list(range(n_qubits // 2))\n",
    "# ghz_qubits = list(range(0, n_qubits, 2))\n",
    "# print(f\"GHZ qubits: {ghz_qubits}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create graph (Demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "G = get_graph(n_qubits, rng, graph_type)\n",
    "\n",
    "positions = get_positions(n_qubits, graph_type)\n",
    "\n",
    "# エッジラベルを作成\n",
    "edge_J_labels = {edge: f\"{G.edges[edge]['J']:.2g}\" for edge in G.edges}\n",
    "edge_cnot_order_labels = {edge: f\"{G.edges[edge]['cnot']['order']}\" for edge in G.edges}\n",
    "\n",
    "# グラフを描画\n",
    "plt.figure(figsize=(10, 3))\n",
    "nx.draw(\n",
    "    G,\n",
    "    pos=positions,\n",
    "    with_labels=True,\n",
    "    node_color=[\"red\" if G.nodes[node][\"hadamard\"] else \"black\" for node in G.nodes],\n",
    "    node_size=300,\n",
    "    edge_color=\"gray\",\n",
    "    font_color=\"white\",\n",
    "    font_size=10,\n",
    ")\n",
    "\n",
    "# エッジの重みを描画\n",
    "nx.draw_networkx_edge_labels(\n",
    "    G,\n",
    "    pos=positions,\n",
    "    edge_labels=edge_J_labels,\n",
    "    font_size=10,\n",
    "    font_color=\"black\",\n",
    "    label_pos=0.6,\n",
    "    verticalalignment=\"top\",\n",
    ")\n",
    "\n",
    "# エッジの 'cnot' 'order' 属性を描画\n",
    "nx.draw_networkx_edge_labels(\n",
    "    G,\n",
    "    pos=positions,\n",
    "    edge_labels=edge_cnot_order_labels,\n",
    "    font_size=10,\n",
    "    font_color=\"green\",\n",
    "    label_pos=0.8,\n",
    "    verticalalignment=\"bottom\",\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary index: 0011111000\n",
      "decimal: 248\n",
      "(1+0j)\n"
     ]
    }
   ],
   "source": [
    "# State |0011...1100> (center qubits are 1 and the rest are 0)\n",
    "leftmost = n_qubits // 4\n",
    "rightmost = leftmost + n_qubits // 2 - 1\n",
    "index = []\n",
    "for i in range(n_qubits):\n",
    "    if leftmost <= i <= rightmost:\n",
    "        index.append(\"1\")\n",
    "    else:\n",
    "        index.append(\"0\")\n",
    "\n",
    "index = \"\".join(index)\n",
    "print(f\"binary index: {index}\")\n",
    "state = Statevector.from_label(index)\n",
    "\n",
    "print(f\"decimal: {int(index, 2)}\")\n",
    "print(state[int(index, 2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non Trotter simulation (directly compute the expectation value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00107791]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 18 instead with accuracy \n",
      "0.0010193052048841622.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00101931]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:412: SparseEfficiencyWarning: splu converted its input to CSC format\n",
      "  warn('splu converted its input to CSC format', SparseEfficiencyWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:302: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
      "  warn('spsolve is more efficient when sparse b '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00181111]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.0018111146349086694.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00181111]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 2/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[8.43736152e-05]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "8.437361519304236e-05.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[8.43736152e-05]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 3/70\n",
      "Sample 4/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.25361834]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.2536183432773276.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.25361834]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 5/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.04483104]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.04483104357883747.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.04483104]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 6/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00455101]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.004551013764236384.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00455101]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 7/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.02434927]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.024349269636967437.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.02434927]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 8/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00258589]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 19 instead with accuracy \n",
      "0.0020105553651839766.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00201056]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 9/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00816048]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 13 instead with accuracy \n",
      "0.0029517672384422383.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00295177]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 10/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00061182]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.0006118163000883784.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00061182]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 11/70\n",
      "Sample 12/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00769415]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.007694149291504889.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00769415]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 13/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.0024504]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.002450397023331709.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.0024504]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 14/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.0039157]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 20 instead with accuracy \n",
      "0.0025693638623558884.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00256936]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 15/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.13838109]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 12 instead with accuracy \n",
      "0.07125087341671031.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.07125087]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 16/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.05569997]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.05569996685022678.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.05569997]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 17/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.05323534]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.05323534045558343.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.05323534]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 18/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.29437658]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.29437658432566977.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.29437658]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 19/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.07072507]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.0707250666237176.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.07072507]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 20/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.01699119]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 20 instead with accuracy \n",
      "0.016700400971019814.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.0167004]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 21/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.01719998]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.0171999759142536.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.01719998]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 22/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00154156]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 19 instead with accuracy \n",
      "0.0002936620191239768.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00029366]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 23/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.01332935]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 18 instead with accuracy \n",
      "0.003205340224781511.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00320534]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 24/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.24121729]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.24121729238471756.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.24121729]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 25/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.0966212]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.0966212004809833.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.0966212]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 26/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.07855813]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 19 instead with accuracy \n",
      "0.038267119796935846.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.03826712]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 27/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00220315]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.002203150444068435.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00220315]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 28/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00975305]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 20 instead with accuracy \n",
      "0.00969035440597412.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00969035]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 29/70\n",
      "Sample 30/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00876071]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.008760712941866424.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00876071]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 31/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00415403]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 20 instead with accuracy \n",
      "0.00404137915392538.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00404138]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 32/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00899475]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.008994754103593005.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00899475]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 33/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.02013941]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 18 instead with accuracy \n",
      "0.009700992518264017.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00970099]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 34/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.0008813]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 19 instead with accuracy \n",
      "0.0006060527043827949.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00060605]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 35/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.35502362]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 16 instead with accuracy \n",
      "0.17943386296374317.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.17943386]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 36/70\n",
      "Sample 37/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.02803662]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.028036616523298266.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.02803662]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 38/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00021025]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.0002102530218104491.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00021025]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 39/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00273042]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.0027304204486105366.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00273042]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 40/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.01750522]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.01750522336800593.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.01750522]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 41/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.05297354]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 19 instead with accuracy \n",
      "0.037018822829926246.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.03701882]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 42/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.10714406]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.10714405724635016.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.10714406]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 43/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.02171169]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.021711692866740743.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.02171169]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 44/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.02011695]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 20 instead with accuracy \n",
      "0.017242146010369334.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.01724215]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 45/70\n",
      "Sample 46/70\n",
      "Sample 47/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.000214]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.00021399996113672192.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.000214]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 48/70\n",
      "Sample 49/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.0061683]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.006168303630314139.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.0061683]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 50/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00119648]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.0011964836678189125.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00119648]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 51/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00016929]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.00016928698045660842.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00016929]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 52/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00011207]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.00011206883146737116.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00011207]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 53/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00038395]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.0003839484405857121.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00038395]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 54/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00066592]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.0006659165140560296.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00066592]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 55/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.08026336]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 14 instead with accuracy \n",
      "0.0038800279566016307.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00388003]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 56/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.3017198]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 15 instead with accuracy \n",
      "0.07247197554019845.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.07247198]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 57/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00077243]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.0007724327581269635.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00077243]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 58/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.08228509]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.08228509319006215.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.08228509]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 59/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.0466818]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.04668180470806452.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.0466818]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 60/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00367472]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.003674717186498963.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00367472]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 61/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.01387141]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.013871412088423418.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.01387141]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 62/70\n",
      "Sample 63/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.06662464]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 20 instead with accuracy \n",
      "0.036774509426159833.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.03677451]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 64/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00652825]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 12 instead with accuracy \n",
      "0.006243015873115447.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00624302]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 65/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.002969]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.002969000208935121.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.002969]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 66/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.26619955]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 19 instead with accuracy \n",
      "0.21481354372081848.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.21481354]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 67/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00337775]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.003377750889742902.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00337775]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 68/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00285642]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.00285642428864217.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00285642]\n",
      "not reaching the requested tolerance 1.52587890625e-05.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 69/70\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Js</th>\n",
       "      <th>expected_value</th>\n",
       "      <th>norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.5479120971119267, -0.12224312049589536, 0.7...</td>\n",
       "      <td>1.582990</td>\n",
       "      <td>9.580142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.09922812420886573, -0.25840395153483753, 0...</td>\n",
       "      <td>0.453302</td>\n",
       "      <td>6.686238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.6552623439851641, 0.2633287982441297, 0.516...</td>\n",
       "      <td>1.100555</td>\n",
       "      <td>8.876921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.9123924684255424, -0.6914210158649043, 0.3...</td>\n",
       "      <td>1.057326</td>\n",
       "      <td>7.928723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.7401569893290567, -0.04859014754813251, -0...</td>\n",
       "      <td>2.430337</td>\n",
       "      <td>6.746732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>[0.2616644807294848, -0.644986835126065, -0.32...</td>\n",
       "      <td>2.544589</td>\n",
       "      <td>7.228165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>[-0.9853710874139687, -0.44395578679837233, 0....</td>\n",
       "      <td>0.095130</td>\n",
       "      <td>8.179614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>[0.44139189343670315, 0.9264224470987592, 0.56...</td>\n",
       "      <td>2.769300</td>\n",
       "      <td>8.050436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>[0.9396302334111388, 0.9691561628632492, -0.42...</td>\n",
       "      <td>6.544680</td>\n",
       "      <td>9.139168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>[-0.020600516366188204, 0.9710803389898524, -0...</td>\n",
       "      <td>2.495537</td>\n",
       "      <td>9.849522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Js  expected_value  \\\n",
       "0   [0.5479120971119267, -0.12224312049589536, 0.7...        1.582990   \n",
       "1   [-0.09922812420886573, -0.25840395153483753, 0...        0.453302   \n",
       "2   [0.6552623439851641, 0.2633287982441297, 0.516...        1.100555   \n",
       "3   [-0.9123924684255424, -0.6914210158649043, 0.3...        1.057326   \n",
       "4   [-0.7401569893290567, -0.04859014754813251, -0...        2.430337   \n",
       "..                                                ...             ...   \n",
       "65  [0.2616644807294848, -0.644986835126065, -0.32...        2.544589   \n",
       "66  [-0.9853710874139687, -0.44395578679837233, 0....        0.095130   \n",
       "67  [0.44139189343670315, 0.9264224470987592, 0.56...        2.769300   \n",
       "68  [0.9396302334111388, 0.9691561628632492, -0.42...        6.544680   \n",
       "69  [-0.020600516366188204, 0.9710803389898524, -0...        2.495537   \n",
       "\n",
       "        norm  \n",
       "0   9.580142  \n",
       "1   6.686238  \n",
       "2   8.876921  \n",
       "3   7.928723  \n",
       "4   6.746732  \n",
       "..       ...  \n",
       "65  7.228165  \n",
       "66  8.179614  \n",
       "67  8.050436  \n",
       "68  9.139168  \n",
       "69  9.849522  \n",
       "\n",
       "[70 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "graphs = []\n",
    "# For debugging\n",
    "# eigvals_abs_max = []\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "for i in range(n_samples):\n",
    "    print(f\"Sample {i}/{n_samples}\")\n",
    "    G = get_graph(n_qubits, rng, graph_type)\n",
    "    Js = [G.edges[edge][\"J\"] for edge in G.edges]\n",
    "    heisenberg = HeisenbergModel(n_qubits, G)\n",
    "\n",
    "    H = heisenberg.H\n",
    "    # H = H.to_matrix(sparse=True)\n",
    "\n",
    "    # state is big endian, so we need to reverse the qubits of the Hamiltonian\n",
    "    H = Operator(H).reverse_qargs().to_matrix()\n",
    "    H = scipy.sparse.csr_matrix(H)\n",
    "    norm = scipy.sparse.linalg.norm(H, ord=2)\n",
    "\n",
    "    fH = scipy.sparse.linalg.expm(-beta * H)\n",
    "    # Compute the expectation value <state|exp(-beta*H)|state>\n",
    "    y = np.vdot(state, fH @ state).real\n",
    "\n",
    "    data.append({\"Js\": Js, \"expected_value\": y, \"norm\": norm})\n",
    "    graphs.append(G)\n",
    "\n",
    "    # For debugging\n",
    "    # eigvals_abs_max.append(max(np.abs(scipy.linalg.eigvals(H.toarray()))))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     70.000000\n",
       "mean      10.600651\n",
       "std       34.164733\n",
       "min        0.095130\n",
       "25%        1.375474\n",
       "50%        2.757324\n",
       "75%        9.339521\n",
       "max      283.573595\n",
       "Name: expected_value, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"expected_value\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers: Index([6, 9, 10, 12, 16, 19, 26, 37, 43, 46, 48, 50, 52, 57], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# Query the 80% quantile\n",
    "q = df[\"expected_value\"].quantile(0.8)\n",
    "filtered_index = df.query(f\"expected_value < @q\").index\n",
    "diffrence = df.index.difference(filtered_index)\n",
    "print(f\"Outliers: {diffrence}\")\n",
    "\n",
    "# Remove outliers\n",
    "df = df.drop(diffrence).reset_index(drop=True)\n",
    "graphs = [graph for i, graph in enumerate(graphs) if i not in diffrence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Js</th>\n",
       "      <th>expected_value</th>\n",
       "      <th>norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.5479120971119267, -0.12224312049589536, 0.7...</td>\n",
       "      <td>1.582990</td>\n",
       "      <td>9.580142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.09922812420886573, -0.25840395153483753, 0...</td>\n",
       "      <td>0.453302</td>\n",
       "      <td>6.686238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.6552623439851641, 0.2633287982441297, 0.516...</td>\n",
       "      <td>1.100555</td>\n",
       "      <td>8.876921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.9123924684255424, -0.6914210158649043, 0.3...</td>\n",
       "      <td>1.057326</td>\n",
       "      <td>7.928723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.7401569893290567, -0.04859014754813251, -0...</td>\n",
       "      <td>2.430337</td>\n",
       "      <td>6.746732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.6095287149936037, -0.22504324193965108, -0....</td>\n",
       "      <td>1.390452</td>\n",
       "      <td>7.885196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.5299977148320512, 0.2694366400011816, 0.107...</td>\n",
       "      <td>5.624548</td>\n",
       "      <td>5.765879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.7068061465363322, -0.5321210282693185, -0.8...</td>\n",
       "      <td>1.090109</td>\n",
       "      <td>6.703631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.9237953290990291, 0.8171613814152141, 0.399...</td>\n",
       "      <td>8.392081</td>\n",
       "      <td>9.360458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.4389259119018736, -0.13581392044979257, 0.2...</td>\n",
       "      <td>1.481529</td>\n",
       "      <td>6.447180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[-0.34027757533442937, -0.7109516222679062, -0...</td>\n",
       "      <td>2.721574</td>\n",
       "      <td>7.355585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[-0.954392257940605, 0.9171184264828907, -0.03...</td>\n",
       "      <td>7.680052</td>\n",
       "      <td>8.047546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.1080722870780988, -0.7828485177291129, 0.34...</td>\n",
       "      <td>1.847303</td>\n",
       "      <td>7.569575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[-0.5395720182102384, -0.9251748876476404, 0.1...</td>\n",
       "      <td>1.005478</td>\n",
       "      <td>7.522891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.7815849817570497, 0.7868932793957264, 0.037...</td>\n",
       "      <td>3.219506</td>\n",
       "      <td>7.392768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[-0.47507896815427064, 0.8736263010675585, -0....</td>\n",
       "      <td>11.765608</td>\n",
       "      <td>8.781429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[-0.6071306685708535, -0.37935265419981046, 0....</td>\n",
       "      <td>2.745348</td>\n",
       "      <td>9.349091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.35531734722571495, -0.7563349907429378, 0.0...</td>\n",
       "      <td>1.387163</td>\n",
       "      <td>6.500069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[-0.7378844968853735, -0.7524923926993108, 0.8...</td>\n",
       "      <td>3.950338</td>\n",
       "      <td>7.147584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.8496168586240542, -0.9502810172274874, 0.11...</td>\n",
       "      <td>1.514930</td>\n",
       "      <td>8.033713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.061539181198106974, 0.21203164140002184, 0....</td>\n",
       "      <td>0.270568</td>\n",
       "      <td>5.386270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[-0.09220623584740051, -0.5043208740972838, -0...</td>\n",
       "      <td>2.242944</td>\n",
       "      <td>8.550812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0.6493283809126826, -0.37933065215185113, -0....</td>\n",
       "      <td>6.528164</td>\n",
       "      <td>10.661281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[-0.8892091816714798, -0.6507170581282946, -0....</td>\n",
       "      <td>1.371577</td>\n",
       "      <td>7.884202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.702263253644412, -0.9130498759744161, -0.63...</td>\n",
       "      <td>11.377287</td>\n",
       "      <td>8.490048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.04750589743527445, -0.7966561941925681, 0.6...</td>\n",
       "      <td>2.385442</td>\n",
       "      <td>10.961561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.6040517605471871, 0.5589550815426578, 0.284...</td>\n",
       "      <td>1.160944</td>\n",
       "      <td>6.878046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[-0.22982100779929304, 0.2791265424742202, -0....</td>\n",
       "      <td>11.133368</td>\n",
       "      <td>5.854286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[-0.3450088711749091, -0.24107184054614206, 0....</td>\n",
       "      <td>0.293391</td>\n",
       "      <td>5.705719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.6971209775472491, 0.30517468112020407, 0.60...</td>\n",
       "      <td>1.959877</td>\n",
       "      <td>7.719660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.6017683521701933, 0.18736400893270821, 0.56...</td>\n",
       "      <td>0.398371</td>\n",
       "      <td>8.325729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[-0.6574173918144224, 0.1299012229448837, 0.14...</td>\n",
       "      <td>4.093477</td>\n",
       "      <td>4.149999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.8624724713802037, -0.7605328229977544, -0.7...</td>\n",
       "      <td>9.411121</td>\n",
       "      <td>7.704435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.7967330947230715, 0.5250642941413046, -0.45...</td>\n",
       "      <td>7.160187</td>\n",
       "      <td>7.392717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[-0.23336035444518033, 0.45937141735475584, 0....</td>\n",
       "      <td>0.179582</td>\n",
       "      <td>7.663223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.6507990223926423, -0.40928194931182027, -0....</td>\n",
       "      <td>1.450140</td>\n",
       "      <td>8.658905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.7584000486154905, -0.43218312427192207, 0.6...</td>\n",
       "      <td>0.544677</td>\n",
       "      <td>11.274471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[-0.8966841659712022, 0.21185035529545537, 0.6...</td>\n",
       "      <td>4.203069</td>\n",
       "      <td>9.411644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[-0.6895740151178182, 0.4692421838703231, -0.6...</td>\n",
       "      <td>8.697506</td>\n",
       "      <td>8.466899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.2728166842155537, 0.1448262999172747, -0.70...</td>\n",
       "      <td>0.666307</td>\n",
       "      <td>8.071577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.22197509407325655, 0.269258234836526, -0.17...</td>\n",
       "      <td>6.456802</td>\n",
       "      <td>5.730031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[-0.05173464981965936, -0.548814263591578, 0.1...</td>\n",
       "      <td>0.519994</td>\n",
       "      <td>4.998201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.09828876719935886, -0.13716360964021979, 0....</td>\n",
       "      <td>3.647253</td>\n",
       "      <td>5.606257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.04055022948113818, 0.5997408215276729, -0.3...</td>\n",
       "      <td>9.124720</td>\n",
       "      <td>8.225373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[-0.6927742018787304, 0.20168081589016174, -0....</td>\n",
       "      <td>5.356119</td>\n",
       "      <td>8.210197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.4108127309680254, -0.2243166096727005, 0.28...</td>\n",
       "      <td>2.056885</td>\n",
       "      <td>7.563094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.978266005367211, 0.1119388560568968, 0.6781...</td>\n",
       "      <td>0.295251</td>\n",
       "      <td>9.147554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[-0.13244194535481402, -0.06134613161919744, -...</td>\n",
       "      <td>5.766763</td>\n",
       "      <td>7.584160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.17289034602959186, -0.013420048298666831, -...</td>\n",
       "      <td>0.911488</td>\n",
       "      <td>6.263957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[-0.8837830365571053, -0.26678323013477523, 0....</td>\n",
       "      <td>2.584785</td>\n",
       "      <td>5.991269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[0.8191044877426998, 0.17424788107396116, 0.70...</td>\n",
       "      <td>0.286682</td>\n",
       "      <td>8.112462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[0.2616644807294848, -0.644986835126065, -0.32...</td>\n",
       "      <td>2.544589</td>\n",
       "      <td>7.228165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>[-0.9853710874139687, -0.44395578679837233, 0....</td>\n",
       "      <td>0.095130</td>\n",
       "      <td>8.179614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>[0.44139189343670315, 0.9264224470987592, 0.56...</td>\n",
       "      <td>2.769300</td>\n",
       "      <td>8.050436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>[0.9396302334111388, 0.9691561628632492, -0.42...</td>\n",
       "      <td>6.544680</td>\n",
       "      <td>9.139168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>[-0.020600516366188204, 0.9710803389898524, -0...</td>\n",
       "      <td>2.495537</td>\n",
       "      <td>9.849522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Js  expected_value  \\\n",
       "0   [0.5479120971119267, -0.12224312049589536, 0.7...        1.582990   \n",
       "1   [-0.09922812420886573, -0.25840395153483753, 0...        0.453302   \n",
       "2   [0.6552623439851641, 0.2633287982441297, 0.516...        1.100555   \n",
       "3   [-0.9123924684255424, -0.6914210158649043, 0.3...        1.057326   \n",
       "4   [-0.7401569893290567, -0.04859014754813251, -0...        2.430337   \n",
       "5   [0.6095287149936037, -0.22504324193965108, -0....        1.390452   \n",
       "6   [0.5299977148320512, 0.2694366400011816, 0.107...        5.624548   \n",
       "7   [0.7068061465363322, -0.5321210282693185, -0.8...        1.090109   \n",
       "8   [0.9237953290990291, 0.8171613814152141, 0.399...        8.392081   \n",
       "9   [0.4389259119018736, -0.13581392044979257, 0.2...        1.481529   \n",
       "10  [-0.34027757533442937, -0.7109516222679062, -0...        2.721574   \n",
       "11  [-0.954392257940605, 0.9171184264828907, -0.03...        7.680052   \n",
       "12  [0.1080722870780988, -0.7828485177291129, 0.34...        1.847303   \n",
       "13  [-0.5395720182102384, -0.9251748876476404, 0.1...        1.005478   \n",
       "14  [0.7815849817570497, 0.7868932793957264, 0.037...        3.219506   \n",
       "15  [-0.47507896815427064, 0.8736263010675585, -0....       11.765608   \n",
       "16  [-0.6071306685708535, -0.37935265419981046, 0....        2.745348   \n",
       "17  [0.35531734722571495, -0.7563349907429378, 0.0...        1.387163   \n",
       "18  [-0.7378844968853735, -0.7524923926993108, 0.8...        3.950338   \n",
       "19  [0.8496168586240542, -0.9502810172274874, 0.11...        1.514930   \n",
       "20  [0.061539181198106974, 0.21203164140002184, 0....        0.270568   \n",
       "21  [-0.09220623584740051, -0.5043208740972838, -0...        2.242944   \n",
       "22  [0.6493283809126826, -0.37933065215185113, -0....        6.528164   \n",
       "23  [-0.8892091816714798, -0.6507170581282946, -0....        1.371577   \n",
       "24  [0.702263253644412, -0.9130498759744161, -0.63...       11.377287   \n",
       "25  [0.04750589743527445, -0.7966561941925681, 0.6...        2.385442   \n",
       "26  [0.6040517605471871, 0.5589550815426578, 0.284...        1.160944   \n",
       "27  [-0.22982100779929304, 0.2791265424742202, -0....       11.133368   \n",
       "28  [-0.3450088711749091, -0.24107184054614206, 0....        0.293391   \n",
       "29  [0.6971209775472491, 0.30517468112020407, 0.60...        1.959877   \n",
       "30  [0.6017683521701933, 0.18736400893270821, 0.56...        0.398371   \n",
       "31  [-0.6574173918144224, 0.1299012229448837, 0.14...        4.093477   \n",
       "32  [0.8624724713802037, -0.7605328229977544, -0.7...        9.411121   \n",
       "33  [0.7967330947230715, 0.5250642941413046, -0.45...        7.160187   \n",
       "34  [-0.23336035444518033, 0.45937141735475584, 0....        0.179582   \n",
       "35  [0.6507990223926423, -0.40928194931182027, -0....        1.450140   \n",
       "36  [0.7584000486154905, -0.43218312427192207, 0.6...        0.544677   \n",
       "37  [-0.8966841659712022, 0.21185035529545537, 0.6...        4.203069   \n",
       "38  [-0.6895740151178182, 0.4692421838703231, -0.6...        8.697506   \n",
       "39  [0.2728166842155537, 0.1448262999172747, -0.70...        0.666307   \n",
       "40  [0.22197509407325655, 0.269258234836526, -0.17...        6.456802   \n",
       "41  [-0.05173464981965936, -0.548814263591578, 0.1...        0.519994   \n",
       "42  [0.09828876719935886, -0.13716360964021979, 0....        3.647253   \n",
       "43  [0.04055022948113818, 0.5997408215276729, -0.3...        9.124720   \n",
       "44  [-0.6927742018787304, 0.20168081589016174, -0....        5.356119   \n",
       "45  [0.4108127309680254, -0.2243166096727005, 0.28...        2.056885   \n",
       "46  [0.978266005367211, 0.1119388560568968, 0.6781...        0.295251   \n",
       "47  [-0.13244194535481402, -0.06134613161919744, -...        5.766763   \n",
       "48  [0.17289034602959186, -0.013420048298666831, -...        0.911488   \n",
       "49  [-0.8837830365571053, -0.26678323013477523, 0....        2.584785   \n",
       "50  [0.8191044877426998, 0.17424788107396116, 0.70...        0.286682   \n",
       "51  [0.2616644807294848, -0.644986835126065, -0.32...        2.544589   \n",
       "52  [-0.9853710874139687, -0.44395578679837233, 0....        0.095130   \n",
       "53  [0.44139189343670315, 0.9264224470987592, 0.56...        2.769300   \n",
       "54  [0.9396302334111388, 0.9691561628632492, -0.42...        6.544680   \n",
       "55  [-0.020600516366188204, 0.9710803389898524, -0...        2.495537   \n",
       "\n",
       "         norm  \n",
       "0    9.580142  \n",
       "1    6.686238  \n",
       "2    8.876921  \n",
       "3    7.928723  \n",
       "4    6.746732  \n",
       "5    7.885196  \n",
       "6    5.765879  \n",
       "7    6.703631  \n",
       "8    9.360458  \n",
       "9    6.447180  \n",
       "10   7.355585  \n",
       "11   8.047546  \n",
       "12   7.569575  \n",
       "13   7.522891  \n",
       "14   7.392768  \n",
       "15   8.781429  \n",
       "16   9.349091  \n",
       "17   6.500069  \n",
       "18   7.147584  \n",
       "19   8.033713  \n",
       "20   5.386270  \n",
       "21   8.550812  \n",
       "22  10.661281  \n",
       "23   7.884202  \n",
       "24   8.490048  \n",
       "25  10.961561  \n",
       "26   6.878046  \n",
       "27   5.854286  \n",
       "28   5.705719  \n",
       "29   7.719660  \n",
       "30   8.325729  \n",
       "31   4.149999  \n",
       "32   7.704435  \n",
       "33   7.392717  \n",
       "34   7.663223  \n",
       "35   8.658905  \n",
       "36  11.274471  \n",
       "37   9.411644  \n",
       "38   8.466899  \n",
       "39   8.071577  \n",
       "40   5.730031  \n",
       "41   4.998201  \n",
       "42   5.606257  \n",
       "43   8.225373  \n",
       "44   8.210197  \n",
       "45   7.563094  \n",
       "46   9.147554  \n",
       "47   7.584160  \n",
       "48   6.263957  \n",
       "49   5.991269  \n",
       "50   8.112462  \n",
       "51   7.228165  \n",
       "52   8.179614  \n",
       "53   8.050436  \n",
       "54   9.139168  \n",
       "55   9.849522  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    56.000000\n",
       "mean      3.382580\n",
       "std       3.210914\n",
       "min       0.095130\n",
       "25%       1.081913\n",
       "50%       2.314193\n",
       "75%       5.423226\n",
       "max      11.765608\n",
       "Name: expected_value, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df)\n",
    "\n",
    "n_samples = len(df)\n",
    "print(f\"Number of samples: {n_samples}\")\n",
    "df[\"expected_value\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    56.000000\n",
       "mean      7.728077\n",
       "std       1.460874\n",
       "min       4.149999\n",
       "25%       6.735957\n",
       "50%       7.801931\n",
       "75%       8.505239\n",
       "max      11.274471\n",
       "Name: norm, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"norm\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check eigvals and Configure params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 11.27447148961441\n",
      "times: [0.0, 0.27864655620298495, 0.5572931124059699, 0.8359396686089549, 1.1145862248119398, 1.3932327810149248, 1.6718793372179097, 1.9505258934208947, 2.2291724496238796, 2.507819005826865]\n"
     ]
    }
   ],
   "source": [
    "n_features = 10  # Number of Fourier features\n",
    "\n",
    "# Parameters for the Fourier feature generation\n",
    "# For shifted Hamiltonian\n",
    "# C = 20 * n_qubits  # upper bound for eigenvalues (WHY?)\n",
    "# times = [2 * np.pi * k / C for k in range(n_features)]\n",
    "\n",
    "# For unshifted Hamiltonian\n",
    "# C = 10 * n_qubits  # upper bound for eigenvalues\n",
    "C = max(df[\"norm\"])\n",
    "times = [np.pi * k / C for k in range(n_features)]\n",
    "\n",
    "print(f\"C: {C}\")\n",
    "print(f\"times: {times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/fourier_learning_ibm\n"
     ]
    }
   ],
   "source": [
    "# Only for CP1\n",
    "%cd fourier_learning_ibm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: This CURRENT_TIME is used for other notebooks.\n",
      "CURRENT_TIME: 2024-12-10T15:41Z\n",
      "Saving data to ./data/2024-12-10T15:41Z\n"
     ]
    }
   ],
   "source": [
    "CURRENT_TIME = (\n",
    "    datetime.now(timezone.utc).isoformat(timespec=\"minutes\").replace(\"+00:00\", \"Z\")\n",
    ")\n",
    "\n",
    "path = f\"./data/{CURRENT_TIME}\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "print(\"Note: This CURRENT_TIME is used for other notebooks.\")\n",
    "print(f\"CURRENT_TIME: {CURRENT_TIME}\")\n",
    "print(f\"Saving data to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save parameters\n",
    "\n",
    "# Save the graphs as a binary file\n",
    "with open(f\"{path}/params_object.pkl\", \"wb\") as f:\n",
    "    pickle.dump(\n",
    "        {\n",
    "            \"graphs\": graphs,\n",
    "            \"Js\": df[\"Js\"].values,\n",
    "            \"expected_values\": df[\"expected_value\"].values,\n",
    "        },\n",
    "        f,\n",
    "    )\n",
    "\n",
    "# Save the parameters as a JSON file\n",
    "with open(f\"{path}/params_text.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"n_samples\": n_samples,\n",
    "            \"n_qubits\": n_qubits,\n",
    "            \"graph_type\": graph_type,\n",
    "            \"backend_qpu_name\": backend_qpu.name,\n",
    "            \"beta\": beta,\n",
    "            \"C\": C,\n",
    "            \"n_features\": n_features,\n",
    "            \"times\": times,\n",
    "        },\n",
    "        f,\n",
    "        indent=4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
