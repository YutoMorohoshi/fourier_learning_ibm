{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo: \n",
    "+ ~~期待値がほぼ 0 になっている理由を探す。回避できるようなら回避~~\n",
    "+ ~~C = 3 * n_qubits の理由~~ (特に理由はない？)\n",
    "+ ~~QPU のばらつき改善~~\n",
    "+ ~~2 次のトロッターにしてみる~~\n",
    "+ ~~GHZ を中心に寄せる。このままだと不要な Trotter gate があるので。~~\n",
    "+ 不要な interaction を削除"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## わかったこと\n",
    "+ ハミルトニアンをシフトさせなければ成功\n",
    "+ times = [2 * np.pi * k / C for k in range(n_features)] は失敗\n",
    "+ times = [np.pi * k / C for k in range(n_features)] は成功"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pip freeze > requirements.txt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/jovyan',\n",
      " '/opt/conda/lib/python311.zip',\n",
      " '/opt/conda/lib/python3.11',\n",
      " '/opt/conda/lib/python3.11/lib-dynload',\n",
      " '',\n",
      " '/opt/conda/lib/python3.11/site-packages',\n",
      " '/home/jovyan/fourier_learning_ibm/']\n"
     ]
    }
   ],
   "source": [
    "# Add the fourier_learning_ibm package to the path\n",
    "import sys, pprint\n",
    "\n",
    "sys.path.append(\"/home/jovyan/fourier_learning_ibm/\")\n",
    "pprint.pprint(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from heisenberg_graph import (\n",
    "    HeisenbergModel,\n",
    "    get_n_steps,\n",
    "    get_graph,\n",
    "    get_positions,\n",
    "    get_initial_layout,\n",
    "    get_prob0,\n",
    "    extract_probs,\n",
    ")\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.quantum_info.operators import Operator\n",
    "from qiskit.quantum_info import SparsePauliOp, Statevector\n",
    "from qiskit.circuit.library import PauliEvolutionGate\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService, SamplerV2 as Sampler, Batch\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit_aer.noise import NoiseModel\n",
    "import mthree\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from datetime import datetime, timezone\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Qiskit Runtime service (this is a one-time setup)\n",
    "# QiskitRuntimeService.save_account(\n",
    "#     token=\"YOUR_API_TOKEN\",\n",
    "#     channel=\"ibm_quantum\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using backend QPU: <IBMBackend('ibm_marrakesh')>\n",
      "Using backend simulator: AerSimulator('aer_simulator')\n",
      "Using backend noisy simulator: AerSimulator('aer_simulator'\n",
      "             noise_model=<NoiseModel on ['sx', 'id', 'x', 'reset', 'measure', 'cz']>)\n"
     ]
    }
   ],
   "source": [
    "# Option1: Use IBM Quantum backend.\n",
    "# Load saved credentials\n",
    "service = QiskitRuntimeService()\n",
    "# backend_qpu = service.least_busy(simulator=False, interactional=True)\n",
    "backend_qpu = service.backend(\"ibm_marrakesh\")\n",
    "\n",
    "# Option2: Use local AerSimulator as the backend.\n",
    "backend_sim = AerSimulator()\n",
    "\n",
    "noise_model = NoiseModel.from_backend(backend_qpu)\n",
    "backend_sim_noisy = AerSimulator(noise_model=noise_model)\n",
    "\n",
    "print(f\"Using backend QPU: {backend_qpu}\")\n",
    "print(f\"Using backend simulator: {backend_sim}\")\n",
    "print(f\"Using backend noisy simulator: {backend_sim_noisy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセット作成 $\\exp(-\\beta H)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 70\n",
    "n_qubits = 6\n",
    "beta = 1\n",
    "\n",
    "graph_type = \"line\"\n",
    "# ghz_qubits = list(range(n_qubits // 2))\n",
    "# ghz_qubits = list(range(0, n_qubits, 2))\n",
    "# print(f\"GHZ qubits: {ghz_qubits}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create graph (Demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "G = get_graph(n_qubits, rng, graph_type)\n",
    "\n",
    "positions = get_positions(n_qubits, graph_type)\n",
    "\n",
    "# エッジラベルを作成\n",
    "edge_J_labels = {edge: f\"{G.edges[edge]['J']:.2g}\" for edge in G.edges}\n",
    "edge_cnot_order_labels = {edge: f\"{G.edges[edge]['cnot']['order']}\" for edge in G.edges}\n",
    "\n",
    "# グラフを描画\n",
    "plt.figure(figsize=(10, 3))\n",
    "nx.draw(\n",
    "    G,\n",
    "    pos=positions,\n",
    "    with_labels=True,\n",
    "    node_color=[\"red\" if G.nodes[node][\"hadamard\"] else \"black\" for node in G.nodes],\n",
    "    node_size=300,\n",
    "    edge_color=\"gray\",\n",
    "    font_color=\"white\",\n",
    "    font_size=10,\n",
    ")\n",
    "\n",
    "# エッジの重みを描画\n",
    "nx.draw_networkx_edge_labels(\n",
    "    G,\n",
    "    pos=positions,\n",
    "    edge_labels=edge_J_labels,\n",
    "    font_size=10,\n",
    "    font_color=\"black\",\n",
    "    label_pos=0.6,\n",
    "    verticalalignment=\"top\",\n",
    ")\n",
    "\n",
    "# エッジの 'cnot' 'order' 属性を描画\n",
    "nx.draw_networkx_edge_labels(\n",
    "    G,\n",
    "    pos=positions,\n",
    "    edge_labels=edge_cnot_order_labels,\n",
    "    font_size=10,\n",
    "    font_color=\"green\",\n",
    "    label_pos=0.8,\n",
    "    verticalalignment=\"bottom\",\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary index: 011100\n",
      "decimal: 28\n",
      "(1+0j)\n"
     ]
    }
   ],
   "source": [
    "# State |0011...1100> (center qubits are 1 and the rest are 0)\n",
    "leftmost = n_qubits // 4\n",
    "rightmost = leftmost + n_qubits // 2 - 1\n",
    "index = []\n",
    "for i in range(n_qubits):\n",
    "    if leftmost <= i <= rightmost:\n",
    "        index.append(\"1\")\n",
    "    else:\n",
    "        index.append(\"0\")\n",
    "\n",
    "index = \"\".join(index)\n",
    "print(f\"binary index: {index}\")\n",
    "state = Statevector.from_label(index)\n",
    "\n",
    "print(f\"decimal: {int(index, 2)}\")\n",
    "print(state[int(index, 2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non Trotter simulation (directly compute the expectation value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0/70\n",
      "Sample 1/70\n",
      "Sample 2/70\n",
      "Sample 3/70\n",
      "Sample 4/70\n",
      "Sample 5/70\n",
      "Sample 6/70\n",
      "Sample 7/70\n",
      "Sample 8/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:412: SparseEfficiencyWarning: splu converted its input to CSC format\n",
      "  warn('splu converted its input to CSC format', SparseEfficiencyWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:302: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
      "  warn('spsolve is more efficient when sparse b '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 9/70\n",
      "Sample 10/70\n",
      "Sample 11/70\n",
      "Sample 12/70\n",
      "Sample 13/70\n",
      "Sample 14/70\n",
      "Sample 15/70\n",
      "Sample 16/70\n",
      "Sample 17/70\n",
      "Sample 18/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[1.08313643e-05]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "Use iteration 21 instead with accuracy \n",
      "1.0831364293842462e-05.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[1.08313643e-05]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00015497]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.0001549740774054273.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00015497]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[9.16848409e-06]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "Use iteration 21 instead with accuracy \n",
      "9.168484087501319e-06.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[9.16848409e-06]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[8.4508862e-06]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "Use iteration 21 instead with accuracy \n",
      "8.450886203561635e-06.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[8.4508862e-06]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.0001905]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.00019050086154349268.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.0001905]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 19/70\n",
      "Sample 20/70\n",
      "Sample 21/70\n",
      "Sample 22/70\n",
      "Sample 23/70\n",
      "Sample 24/70\n",
      "Sample 25/70\n",
      "Sample 26/70\n",
      "Sample 27/70\n",
      "Sample 28/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[5.9123715e-05]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "Use iteration 21 instead with accuracy \n",
      "5.912371500335981e-05.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[5.9123715e-05]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[8.92559277e-05]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "Use iteration 21 instead with accuracy \n",
      "8.925592766030392e-05.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[8.92559277e-05]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[6.43656914e-05]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "Use iteration 21 instead with accuracy \n",
      "6.436569140817674e-05.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[6.43656914e-05]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 29/70\n",
      "Sample 30/70\n",
      "Sample 31/70\n",
      "Sample 32/70\n",
      "Sample 33/70\n",
      "Sample 34/70\n",
      "Sample 35/70\n",
      "Sample 36/70\n",
      "Sample 37/70\n",
      "Sample 38/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[5.38864291e-06]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "Use iteration 21 instead with accuracy \n",
      "5.388642914502383e-06.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[5.38864292e-06]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.0006847]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "Use iteration 17 instead with accuracy \n",
      "0.00021863045927917265.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00021863]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00098166]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.0009816600707522676.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00098166]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00038779]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.0003877896862768791.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00038779]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[4.60640038e-06]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "Use iteration 19 instead with accuracy \n",
      "3.928735438021224e-06.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[3.92873544e-06]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 39/70\n",
      "Sample 40/70\n",
      "Sample 41/70\n",
      "Sample 42/70\n",
      "Sample 43/70\n",
      "Sample 44/70\n",
      "Sample 45/70\n",
      "Sample 46/70\n",
      "Sample 47/70\n",
      "Sample 48/70\n",
      "Sample 49/70\n",
      "Sample 50/70\n",
      "Sample 51/70\n",
      "Sample 52/70\n",
      "Sample 53/70\n",
      "Sample 54/70\n",
      "Sample 55/70\n",
      "Sample 56/70\n",
      "Sample 57/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[9.10168509e-05]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "Use iteration 20 instead with accuracy \n",
      "5.3411616129577954e-05.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[5.34116161e-05]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.01557749]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.01557748869659732.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.01557749]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[5.01379874e-06]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "Use iteration 19 instead with accuracy \n",
      "2.7214084339573263e-06.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[2.72140843e-06]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 58/70\n",
      "Sample 59/70\n",
      "Sample 60/70\n",
      "Sample 61/70\n",
      "Sample 62/70\n",
      "Sample 63/70\n",
      "Sample 64/70\n",
      "Sample 65/70\n",
      "Sample 66/70\n",
      "Sample 67/70\n",
      "Sample 68/70\n",
      "Sample 69/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00133595]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.0013359450158600345.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00133595]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.0002123]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "Use iteration 21 instead with accuracy \n",
      "0.0002122994874201518.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/opt/conda/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "[0.0002123]\n",
      "not reaching the requested tolerance 9.5367431640625e-07.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Js</th>\n",
       "      <th>expected_value</th>\n",
       "      <th>norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.5479120971119267, -0.12224312049589536, 0.7...</td>\n",
       "      <td>7.391106</td>\n",
       "      <td>4.777271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.9512447032735118, 0.5222794039807059, 0.572...</td>\n",
       "      <td>7.380861</td>\n",
       "      <td>5.226882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.25840395153483753, 0.8535299776972036, 0.2...</td>\n",
       "      <td>1.560675</td>\n",
       "      <td>4.616894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.5455225564304462, 0.1091695740316696, -0.8...</td>\n",
       "      <td>5.663484</td>\n",
       "      <td>4.765353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.5161754801707477, -0.2909480637402633, 0.94...</td>\n",
       "      <td>16.957718</td>\n",
       "      <td>6.473239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>[0.30517468112020407, 0.6087836558941548, 0.06...</td>\n",
       "      <td>2.084263</td>\n",
       "      <td>3.027240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>[0.46978632462058156, -0.5951908137485633, 0.3...</td>\n",
       "      <td>24.527443</td>\n",
       "      <td>4.787805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>[0.2287594810838396, -0.8098085035401308, 0.45...</td>\n",
       "      <td>4.136595</td>\n",
       "      <td>5.479821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>[-0.7251841399243957, 0.9177604918181608, 0.60...</td>\n",
       "      <td>0.559161</td>\n",
       "      <td>5.350351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>[0.5902296779661718, 0.8920541256346606, -0.49...</td>\n",
       "      <td>10.299132</td>\n",
       "      <td>5.030262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Js  expected_value  \\\n",
       "0   [0.5479120971119267, -0.12224312049589536, 0.7...        7.391106   \n",
       "1   [0.9512447032735118, 0.5222794039807059, 0.572...        7.380861   \n",
       "2   [-0.25840395153483753, 0.8535299776972036, 0.2...        1.560675   \n",
       "3   [-0.5455225564304462, 0.1091695740316696, -0.8...        5.663484   \n",
       "4   [0.5161754801707477, -0.2909480637402633, 0.94...       16.957718   \n",
       "..                                                ...             ...   \n",
       "65  [0.30517468112020407, 0.6087836558941548, 0.06...        2.084263   \n",
       "66  [0.46978632462058156, -0.5951908137485633, 0.3...       24.527443   \n",
       "67  [0.2287594810838396, -0.8098085035401308, 0.45...        4.136595   \n",
       "68  [-0.7251841399243957, 0.9177604918181608, 0.60...        0.559161   \n",
       "69  [0.5902296779661718, 0.8920541256346606, -0.49...       10.299132   \n",
       "\n",
       "        norm  \n",
       "0   4.777271  \n",
       "1   5.226882  \n",
       "2   4.616894  \n",
       "3   4.765353  \n",
       "4   6.473239  \n",
       "..       ...  \n",
       "65  3.027240  \n",
       "66  4.787805  \n",
       "67  5.479821  \n",
       "68  5.350351  \n",
       "69  5.030262  \n",
       "\n",
       "[70 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "graphs = []\n",
    "# For debugging\n",
    "eigvals_abs_max = []\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "for i in range(n_samples):\n",
    "    print(f\"Sample {i}/{n_samples}\")\n",
    "    G = get_graph(n_qubits, rng, graph_type)\n",
    "    Js = [G.edges[edge][\"J\"] for edge in G.edges]\n",
    "    heisenberg = HeisenbergModel(n_qubits, G)\n",
    "\n",
    "    H = heisenberg.H\n",
    "    # H = H.to_matrix(sparse=True)\n",
    "\n",
    "    # state is big endian, so we need to reverse the qubits of the Hamiltonian\n",
    "    H = Operator(H).reverse_qargs().to_matrix()\n",
    "    H = scipy.sparse.csr_matrix(H)\n",
    "    norm = scipy.sparse.linalg.norm(H, ord=2)\n",
    "\n",
    "    fH = scipy.sparse.linalg.expm(-beta * H)\n",
    "    # Compute the expectation value <state|exp(-beta*H)|state>\n",
    "    y = np.vdot(state, fH @ state).real\n",
    "\n",
    "    data.append({\"Js\": Js, \"expected_value\": y, \"norm\": norm})\n",
    "    graphs.append(G)\n",
    "\n",
    "    # For debugging\n",
    "    eigvals_abs_max.append(max(np.abs(scipy.linalg.eigvals(H.toarray()))))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.777270975223148,\n",
       " 5.22688204004276,\n",
       " 4.616894354722351,\n",
       " 4.765353065117219,\n",
       " 6.473239450320756,\n",
       " 5.3965025669150695,\n",
       " 3.536246841637966,\n",
       " 4.500417660536058,\n",
       " 4.387042545981708,\n",
       " 4.203431956530978,\n",
       " 4.386158557185928,\n",
       " 3.819129223605897,\n",
       " 2.903032796801689,\n",
       " 3.2690473845491623,\n",
       " 5.361732082858737,\n",
       " 3.321339706090131,\n",
       " 4.602418721447707,\n",
       " 4.636437714263105,\n",
       " 3.816877712398598,\n",
       " 4.775069190232952,\n",
       " 6.01511529106666,\n",
       " 4.53461393481445,\n",
       " 4.123828370389493,\n",
       " 4.451417602100706,\n",
       " 5.489267893056582,\n",
       " 3.870718935433648,\n",
       " 3.6016411054868,\n",
       " 6.079841940244588,\n",
       " 2.7273259149329796,\n",
       " 4.553056246451277,\n",
       " 5.519428700994197,\n",
       " 3.990964036243303,\n",
       " 5.839893665502012,\n",
       " 5.526075120767958,\n",
       " 5.071398720498485,\n",
       " 5.757266033607996,\n",
       " 4.974769345305574,\n",
       " 4.363725957860937,\n",
       " 5.725891839248706,\n",
       " 4.54344075772695,\n",
       " 4.927448319195041,\n",
       " 4.937574184994487,\n",
       " 3.7659274324914858,\n",
       " 4.866403067429551,\n",
       " 3.443102120595782,\n",
       " 5.71964844291052,\n",
       " 6.147890828840132,\n",
       " 4.852846366969035,\n",
       " 3.599061555663919,\n",
       " 2.827028534651929,\n",
       " 3.3791687116823392,\n",
       " 4.4423533704064715,\n",
       " 5.408385957033522,\n",
       " 7.414563484121284,\n",
       " 5.944163212653943,\n",
       " 3.4934220343680535,\n",
       " 5.218093504957392,\n",
       " 5.276258854362042,\n",
       " 7.155502695154841,\n",
       " 6.148963037546741,\n",
       " 4.4049750690985645,\n",
       " 3.309875266758985,\n",
       " 2.6621176967830675,\n",
       " 4.312198679335198,\n",
       " 4.9389146273614895,\n",
       " 3.0272402937837533,\n",
       " 4.7878055106690605,\n",
       " 5.479820679993771,\n",
       " 5.350350786477236,\n",
       " 5.030262412697053]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For debugging\n",
    "eigvals_abs_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     70.000000\n",
       "mean       8.480972\n",
       "std       17.369696\n",
       "min        0.238580\n",
       "25%        1.685499\n",
       "50%        3.516698\n",
       "75%        7.098143\n",
       "max      124.721404\n",
       "Name: expected_value, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"expected_value\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers: Index([4, 9, 20, 27, 30, 34, 37, 38, 43, 45, 58, 59, 66, 69], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# Query the 80% quantile\n",
    "q = df[\"expected_value\"].quantile(0.8)\n",
    "filtered_index = df.query(f\"expected_value < @q\").index\n",
    "diffrence = df.index.difference(filtered_index)\n",
    "print(f\"Outliers: {diffrence}\")\n",
    "\n",
    "# Remove outliers\n",
    "df = df.drop(diffrence).reset_index(drop=True)\n",
    "graphs = [graph for i, graph in enumerate(graphs) if i not in diffrence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Js</th>\n",
       "      <th>expected_value</th>\n",
       "      <th>norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.5479120971119267, -0.12224312049589536, 0.7...</td>\n",
       "      <td>7.391106</td>\n",
       "      <td>4.777271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.9512447032735118, 0.5222794039807059, 0.572...</td>\n",
       "      <td>7.380861</td>\n",
       "      <td>5.226882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.25840395153483753, 0.8535299776972036, 0.2...</td>\n",
       "      <td>1.560675</td>\n",
       "      <td>4.616894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.5455225564304462, 0.1091695740316696, -0.8...</td>\n",
       "      <td>5.663484</td>\n",
       "      <td>4.765353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.6107225842960649, -0.06655799254593164, -0...</td>\n",
       "      <td>1.889904</td>\n",
       "      <td>5.396503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.48952431181563427, 0.93501946486842, -0.348...</td>\n",
       "      <td>2.056023</td>\n",
       "      <td>3.536247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[-0.6210572818314286, -0.7401569893290567, -0....</td>\n",
       "      <td>1.492621</td>\n",
       "      <td>4.500418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[-0.12569616225533853, 0.6653563921156749, 0.4...</td>\n",
       "      <td>0.238580</td>\n",
       "      <td>4.387043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[-0.6001835950497834, -0.985275460497989, 0.57...</td>\n",
       "      <td>1.960940</td>\n",
       "      <td>4.386159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.5614580620439358, -0.08216844892332009, 0.1...</td>\n",
       "      <td>5.800941</td>\n",
       "      <td>3.819129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.3368059235809433, -0.057807587713734954, 0....</td>\n",
       "      <td>3.831170</td>\n",
       "      <td>2.903033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.10715880131599165, 0.11841432149082709, -0....</td>\n",
       "      <td>1.853173</td>\n",
       "      <td>3.269047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[-0.5708306543609416, -0.1829427125507277, 0.7...</td>\n",
       "      <td>1.506651</td>\n",
       "      <td>5.361732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[-0.4372322159560069, -0.41281248446663277, 0....</td>\n",
       "      <td>0.636416</td>\n",
       "      <td>3.321340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.3286270806547751, -0.18722627711985895, 0.6...</td>\n",
       "      <td>3.370942</td>\n",
       "      <td>4.602419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[-0.8199042784487165, 0.4447187011929006, -0.0...</td>\n",
       "      <td>1.120481</td>\n",
       "      <td>4.636438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[-0.6953757945736632, 0.39264075015547206, -0....</td>\n",
       "      <td>1.260041</td>\n",
       "      <td>3.816878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.2605651862377769, -0.27637477889321915, -0....</td>\n",
       "      <td>3.334174</td>\n",
       "      <td>4.775069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0.4337803783179912, -0.10127699571242266, -0....</td>\n",
       "      <td>3.170910</td>\n",
       "      <td>4.534614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[-0.08844742033277786, -0.5952732704095394, -0...</td>\n",
       "      <td>5.710799</td>\n",
       "      <td>4.123828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0.713228568184751, 0.5170390596704202, 0.4389...</td>\n",
       "      <td>1.679454</td>\n",
       "      <td>4.451418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0.16819593782547115, 0.29969320310964, -0.831...</td>\n",
       "      <td>4.701095</td>\n",
       "      <td>5.489268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[-0.012018361510962139, -0.34027757533442937, ...</td>\n",
       "      <td>2.455891</td>\n",
       "      <td>3.870719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[-0.6588140629262278, 0.8502402367535944, 0.16...</td>\n",
       "      <td>0.591185</td>\n",
       "      <td>3.601641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[-0.026683338323679306, -0.01858601129095816, ...</td>\n",
       "      <td>0.558696</td>\n",
       "      <td>2.727326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[-0.46604867381621284, -0.33686200531489563, 0...</td>\n",
       "      <td>2.760069</td>\n",
       "      <td>4.553056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.3444801860796234, -0.43753243232198336, 0.3...</td>\n",
       "      <td>3.507420</td>\n",
       "      <td>3.990964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[-0.7845181080882069, 0.8320236902752158, -0.5...</td>\n",
       "      <td>1.876509</td>\n",
       "      <td>5.839894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[-0.2581554322751225, 0.6595794862648263, 0.61...</td>\n",
       "      <td>0.297693</td>\n",
       "      <td>5.526075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[-0.910178761215342, -0.12980587999392412, 0.9...</td>\n",
       "      <td>7.008729</td>\n",
       "      <td>5.757266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.7815849817570497, 0.7868932793957264, 0.037...</td>\n",
       "      <td>2.551204</td>\n",
       "      <td>4.974769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[-0.6414633836845218, 0.198765583041687, 0.749...</td>\n",
       "      <td>0.885855</td>\n",
       "      <td>4.543441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.5548096764823551, 0.9436528521219347, 0.001...</td>\n",
       "      <td>4.930559</td>\n",
       "      <td>4.927448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[-0.5406879400022895, -0.7363555644269579, 0.3...</td>\n",
       "      <td>1.703635</td>\n",
       "      <td>4.937574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.38852487128577295, 0.16223321844180472, -0....</td>\n",
       "      <td>6.896491</td>\n",
       "      <td>3.765927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[-0.3981026164381205, -0.02283190929693335, 0....</td>\n",
       "      <td>7.957902</td>\n",
       "      <td>3.443102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[-0.7193208058721747, -0.16177136136739234, 0....</td>\n",
       "      <td>0.499772</td>\n",
       "      <td>6.147891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.6087218312259415, -0.06523679688941697, 0.5...</td>\n",
       "      <td>7.127948</td>\n",
       "      <td>4.852846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.6588572297654727, 0.5936341766503235, -0.53...</td>\n",
       "      <td>4.309069</td>\n",
       "      <td>3.599062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.7354779075520224, 0.20621431467745133, -0.1...</td>\n",
       "      <td>5.071745</td>\n",
       "      <td>2.827029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.30386205115994835, 0.7349812635046498, -0.0...</td>\n",
       "      <td>1.451328</td>\n",
       "      <td>3.379169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.4920285604868928, 0.6331375268478208, -0.78...</td>\n",
       "      <td>3.525975</td>\n",
       "      <td>4.442353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[-0.7076535116146034, 0.6493283809126826, -0.3...</td>\n",
       "      <td>1.025986</td>\n",
       "      <td>5.408382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[-0.6689365545294437, -0.4305598353241289, -0....</td>\n",
       "      <td>6.162553</td>\n",
       "      <td>7.414563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[-0.8892091816714798, -0.6507170581282946, -0....</td>\n",
       "      <td>4.275085</td>\n",
       "      <td>5.944163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[-0.21273908633594352, -0.3640178060959012, 0....</td>\n",
       "      <td>4.886602</td>\n",
       "      <td>3.493422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[-0.9130498759744161, -0.6370031808069518, -0....</td>\n",
       "      <td>2.611576</td>\n",
       "      <td>5.218094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[-0.16747514859361545, -0.901491760144812, -0....</td>\n",
       "      <td>6.505354</td>\n",
       "      <td>5.276259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.557992709156258, -0.7308955831737058, 0.072...</td>\n",
       "      <td>2.541846</td>\n",
       "      <td>4.404975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[-0.07440126881296827, -0.22982100779929304, 0...</td>\n",
       "      <td>1.641879</td>\n",
       "      <td>3.309875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[-0.0442454519525084, -0.16622126281022997, -0...</td>\n",
       "      <td>2.128857</td>\n",
       "      <td>2.662118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[-0.3450088711749091, -0.24107184054614206, 0....</td>\n",
       "      <td>0.585430</td>\n",
       "      <td>4.312199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>[0.8326960390763558, -0.03817914339984285, -0....</td>\n",
       "      <td>4.928844</td>\n",
       "      <td>4.938915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>[0.30517468112020407, 0.6087836558941548, 0.06...</td>\n",
       "      <td>2.084263</td>\n",
       "      <td>3.027240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>[0.2287594810838396, -0.8098085035401308, 0.45...</td>\n",
       "      <td>4.136595</td>\n",
       "      <td>5.479821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>[-0.7251841399243957, 0.9177604918181608, 0.60...</td>\n",
       "      <td>0.559161</td>\n",
       "      <td>5.350351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Js  expected_value  \\\n",
       "0   [0.5479120971119267, -0.12224312049589536, 0.7...        7.391106   \n",
       "1   [0.9512447032735118, 0.5222794039807059, 0.572...        7.380861   \n",
       "2   [-0.25840395153483753, 0.8535299776972036, 0.2...        1.560675   \n",
       "3   [-0.5455225564304462, 0.1091695740316696, -0.8...        5.663484   \n",
       "4   [-0.6107225842960649, -0.06655799254593164, -0...        1.889904   \n",
       "5   [0.48952431181563427, 0.93501946486842, -0.348...        2.056023   \n",
       "6   [-0.6210572818314286, -0.7401569893290567, -0....        1.492621   \n",
       "7   [-0.12569616225533853, 0.6653563921156749, 0.4...        0.238580   \n",
       "8   [-0.6001835950497834, -0.985275460497989, 0.57...        1.960940   \n",
       "9   [0.5614580620439358, -0.08216844892332009, 0.1...        5.800941   \n",
       "10  [0.3368059235809433, -0.057807587713734954, 0....        3.831170   \n",
       "11  [0.10715880131599165, 0.11841432149082709, -0....        1.853173   \n",
       "12  [-0.5708306543609416, -0.1829427125507277, 0.7...        1.506651   \n",
       "13  [-0.4372322159560069, -0.41281248446663277, 0....        0.636416   \n",
       "14  [0.3286270806547751, -0.18722627711985895, 0.6...        3.370942   \n",
       "15  [-0.8199042784487165, 0.4447187011929006, -0.0...        1.120481   \n",
       "16  [-0.6953757945736632, 0.39264075015547206, -0....        1.260041   \n",
       "17  [0.2605651862377769, -0.27637477889321915, -0....        3.334174   \n",
       "18  [0.4337803783179912, -0.10127699571242266, -0....        3.170910   \n",
       "19  [-0.08844742033277786, -0.5952732704095394, -0...        5.710799   \n",
       "20  [0.713228568184751, 0.5170390596704202, 0.4389...        1.679454   \n",
       "21  [0.16819593782547115, 0.29969320310964, -0.831...        4.701095   \n",
       "22  [-0.012018361510962139, -0.34027757533442937, ...        2.455891   \n",
       "23  [-0.6588140629262278, 0.8502402367535944, 0.16...        0.591185   \n",
       "24  [-0.026683338323679306, -0.01858601129095816, ...        0.558696   \n",
       "25  [-0.46604867381621284, -0.33686200531489563, 0...        2.760069   \n",
       "26  [0.3444801860796234, -0.43753243232198336, 0.3...        3.507420   \n",
       "27  [-0.7845181080882069, 0.8320236902752158, -0.5...        1.876509   \n",
       "28  [-0.2581554322751225, 0.6595794862648263, 0.61...        0.297693   \n",
       "29  [-0.910178761215342, -0.12980587999392412, 0.9...        7.008729   \n",
       "30  [0.7815849817570497, 0.7868932793957264, 0.037...        2.551204   \n",
       "31  [-0.6414633836845218, 0.198765583041687, 0.749...        0.885855   \n",
       "32  [0.5548096764823551, 0.9436528521219347, 0.001...        4.930559   \n",
       "33  [-0.5406879400022895, -0.7363555644269579, 0.3...        1.703635   \n",
       "34  [0.38852487128577295, 0.16223321844180472, -0....        6.896491   \n",
       "35  [-0.3981026164381205, -0.02283190929693335, 0....        7.957902   \n",
       "36  [-0.7193208058721747, -0.16177136136739234, 0....        0.499772   \n",
       "37  [0.6087218312259415, -0.06523679688941697, 0.5...        7.127948   \n",
       "38  [0.6588572297654727, 0.5936341766503235, -0.53...        4.309069   \n",
       "39  [0.7354779075520224, 0.20621431467745133, -0.1...        5.071745   \n",
       "40  [0.30386205115994835, 0.7349812635046498, -0.0...        1.451328   \n",
       "41  [0.4920285604868928, 0.6331375268478208, -0.78...        3.525975   \n",
       "42  [-0.7076535116146034, 0.6493283809126826, -0.3...        1.025986   \n",
       "43  [-0.6689365545294437, -0.4305598353241289, -0....        6.162553   \n",
       "44  [-0.8892091816714798, -0.6507170581282946, -0....        4.275085   \n",
       "45  [-0.21273908633594352, -0.3640178060959012, 0....        4.886602   \n",
       "46  [-0.9130498759744161, -0.6370031808069518, -0....        2.611576   \n",
       "47  [-0.16747514859361545, -0.901491760144812, -0....        6.505354   \n",
       "48  [0.557992709156258, -0.7308955831737058, 0.072...        2.541846   \n",
       "49  [-0.07440126881296827, -0.22982100779929304, 0...        1.641879   \n",
       "50  [-0.0442454519525084, -0.16622126281022997, -0...        2.128857   \n",
       "51  [-0.3450088711749091, -0.24107184054614206, 0....        0.585430   \n",
       "52  [0.8326960390763558, -0.03817914339984285, -0....        4.928844   \n",
       "53  [0.30517468112020407, 0.6087836558941548, 0.06...        2.084263   \n",
       "54  [0.2287594810838396, -0.8098085035401308, 0.45...        4.136595   \n",
       "55  [-0.7251841399243957, 0.9177604918181608, 0.60...        0.559161   \n",
       "\n",
       "        norm  \n",
       "0   4.777271  \n",
       "1   5.226882  \n",
       "2   4.616894  \n",
       "3   4.765353  \n",
       "4   5.396503  \n",
       "5   3.536247  \n",
       "6   4.500418  \n",
       "7   4.387043  \n",
       "8   4.386159  \n",
       "9   3.819129  \n",
       "10  2.903033  \n",
       "11  3.269047  \n",
       "12  5.361732  \n",
       "13  3.321340  \n",
       "14  4.602419  \n",
       "15  4.636438  \n",
       "16  3.816878  \n",
       "17  4.775069  \n",
       "18  4.534614  \n",
       "19  4.123828  \n",
       "20  4.451418  \n",
       "21  5.489268  \n",
       "22  3.870719  \n",
       "23  3.601641  \n",
       "24  2.727326  \n",
       "25  4.553056  \n",
       "26  3.990964  \n",
       "27  5.839894  \n",
       "28  5.526075  \n",
       "29  5.757266  \n",
       "30  4.974769  \n",
       "31  4.543441  \n",
       "32  4.927448  \n",
       "33  4.937574  \n",
       "34  3.765927  \n",
       "35  3.443102  \n",
       "36  6.147891  \n",
       "37  4.852846  \n",
       "38  3.599062  \n",
       "39  2.827029  \n",
       "40  3.379169  \n",
       "41  4.442353  \n",
       "42  5.408382  \n",
       "43  7.414563  \n",
       "44  5.944163  \n",
       "45  3.493422  \n",
       "46  5.218094  \n",
       "47  5.276259  \n",
       "48  4.404975  \n",
       "49  3.309875  \n",
       "50  2.662118  \n",
       "51  4.312199  \n",
       "52  4.938915  \n",
       "53  3.027240  \n",
       "54  5.479821  \n",
       "55  5.350351  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    56.000000\n",
       "mean      3.172360\n",
       "std       2.200682\n",
       "min       0.238580\n",
       "25%       1.503144\n",
       "50%       2.546525\n",
       "75%       4.897163\n",
       "max       7.957902\n",
       "Name: expected_value, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df)\n",
    "\n",
    "n_samples = len(df)\n",
    "print(f\"Number of samples: {n_samples}\")\n",
    "df[\"expected_value\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    56.000000\n",
       "mean      4.475802\n",
       "std       0.974165\n",
       "min       2.662118\n",
       "25%       3.724856\n",
       "50%       4.539027\n",
       "75%       5.220291\n",
       "max       7.414563\n",
       "Name: norm, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"norm\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check eigvals and Configure params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of eigenvalues\n",
    "# print(f\"Number of samples: {n_samples}\")\n",
    "# eigvals_array = np.array(eigvals_list).flatten()\n",
    "# plt.hist(eigvals_array, bins=50)\n",
    "# plt.xlabel(\"Eigenvalues\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.title(\"Eigenvalues of Hamiltonian\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 7.414563484121309\n",
      "times: [0.0, 0.4237056787385643, 0.8474113574771286, 1.271117036215693, 1.6948227149542572]\n"
     ]
    }
   ],
   "source": [
    "n_features = 5  # Number of Fourier features\n",
    "\n",
    "# Parameters for the Fourier feature generation\n",
    "# For shifted Hamiltonian\n",
    "# C = 20 * n_qubits  # upper bound for eigenvalues (WHY?)\n",
    "# times = [2 * np.pi * k / C for k in range(n_features)]\n",
    "\n",
    "# For unshifted Hamiltonian\n",
    "# C = 10 * n_qubits  # upper bound for eigenvalues\n",
    "C = max(df[\"norm\"])\n",
    "times = [np.pi * k / C for k in range(n_features)]\n",
    "\n",
    "print(f\"C: {C}\")\n",
    "print(f\"times: {times}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/fourier_learning_ibm\n"
     ]
    }
   ],
   "source": [
    "# Only for CP1\n",
    "%cd fourier_learning_ibm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: This CURRENT_TIME is used for other notebooks.\n",
      "CURRENT_TIME: 2024-12-10T09:58Z\n",
      "Saving data to ./data/2024-12-10T09:58Z\n"
     ]
    }
   ],
   "source": [
    "CURRENT_TIME = (\n",
    "    datetime.now(timezone.utc).isoformat(timespec=\"minutes\").replace(\"+00:00\", \"Z\")\n",
    ")\n",
    "\n",
    "path = f\"./data/{CURRENT_TIME}\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "print(\"Note: This CURRENT_TIME is used for other notebooks.\")\n",
    "print(f\"CURRENT_TIME: {CURRENT_TIME}\")\n",
    "print(f\"Saving data to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save parameters\n",
    "\n",
    "# Save the graphs as a binary file\n",
    "with open(f\"{path}/params_object.pkl\", \"wb\") as f:\n",
    "    pickle.dump(\n",
    "        {\n",
    "            \"graphs\": graphs,\n",
    "            \"Js\": df[\"Js\"].values,\n",
    "            \"expected_values\": df[\"expected_value\"].values,\n",
    "        },\n",
    "        f,\n",
    "    )\n",
    "\n",
    "# Save the parameters as a JSON file\n",
    "with open(f\"{path}/params_text.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"n_samples\": n_samples,\n",
    "            \"n_qubits\": n_qubits,\n",
    "            \"graph_type\": graph_type,\n",
    "            \"backend_qpu_name\": backend_qpu.name,\n",
    "            \"beta\": beta,\n",
    "            \"C\": C,\n",
    "            \"n_features\": n_features,\n",
    "            \"times\": times,\n",
    "        },\n",
    "        f,\n",
    "        indent=4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
